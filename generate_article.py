#!/usr/bin/env python3
"""
The Jury - è‡ªå‹•è¨˜äº‹ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆGemini APIç‰ˆï¼‰
æœˆãƒ»æ°´ãƒ»é‡‘ã«å®Ÿè¡Œã•ã‚Œã€æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã¦ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼è¨˜äº‹ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹
"""
import os
import json
import re
import sys
import base64
import datetime
import time
import urllib.request
import urllib.parse
import urllib.error
import xml.etree.ElementTree as ET
import html as html_module
from pathlib import Path

# ===== è¨­å®š =====
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://jyikdveqhvimtyovkgbs.supabase.co")
SUPABASE_ANON_KEY = os.environ.get("SUPABASE_ANON_KEY", "sb_publishable_LQ-cUMnaam3q1muTdmqtVg_18H23SHM")
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL", "")

# ===== Gemini APIå‘¼ã³å‡ºã— =====
def call_gemini(prompt: str, model: str = "gemini-2.0-flash") -> str:
    """Gemini APIã‚’å‘¼ã³å‡ºã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    import urllib.request
    import urllib.error

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.85,
            "maxOutputTokens": 8192,
        }
    }
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
    try:
        with urllib.request.urlopen(req, timeout=120) as resp:
            result = json.loads(resp.read().decode("utf-8"))
            return result["candidates"][0]["content"]["parts"][0]["text"]
    except urllib.error.HTTPError as e:
        print(f"âŒ Gemini API ã‚¨ãƒ©ãƒ¼: {e.code} {e.read().decode()}")
        sys.exit(1)

# ===== ä½¿ç”¨æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ =====
def load_used_news() -> list:
    """éå»ã«ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    used_file = Path(__file__).parent / "used_news.json"
    if used_file.exists():
        return json.loads(used_file.read_text(encoding="utf-8"))
    return []

def save_used_news(used: list, title: str):
    """ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨˜éŒ²ã™ã‚‹ï¼ˆ50ä»¶ã¾ã§ä¿æŒï¼‰"""
    used_file = Path(__file__).parent / "used_news.json"
    used.append(title)
    used_file.write_text(json.dumps(used[-50:], ensure_ascii=False, indent=2), encoding="utf-8")

# ===== Google News RSSå–å¾— =====
def fetch_rss_candidates() -> list:
    """Google News RSSã‹ã‚‰AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹"""
    query = urllib.parse.quote("AI äººå·¥çŸ¥èƒ½ ç”ŸæˆAI LLM")
    url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=15) as resp:
            content = resp.read()
        root = ET.fromstring(content)
        items = root.findall(".//item")
        candidates = []
        for item in items[:20]:  # ä¸Šä½20ä»¶ã‚’å€™è£œã«
            title = html_module.unescape(item.findtext("title", ""))
            link = item.findtext("link", "")
            pub = item.findtext("pubDate", "")
            source_el = item.find("source")
            source = source_el.text if source_el is not None else "ä¸æ˜"
            source_url = source_el.get("url", "") if source_el is not None else ""
            candidates.append({
                "title": title,
                "link": link,
                "pub": pub,
                "source": source,
                "source_url": source_url,
            })
        print(f"âœ… Google News RSSå–å¾—å®Œäº†: {len(candidates)}ä»¶")
        return candidates
    except Exception as e:
        print(f"âš ï¸ RSSå–å¾—å¤±æ•—ï¼ˆGeminiãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆï¼‰: {e}")
        return []

# ===== ãƒ‹ãƒ¥ãƒ¼ã‚¹é¸æŠœï¼ˆRSS + Geminiï¼‰ =====
def fetch_top_ai_news() -> dict:
    """ã‚°ãƒ¼ã‚°ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹RSSã‹ã‚‰å€™è£œã‚’å–å¾—ã—ã€GeminiãŒæœ€é©ãª1ä»¶ã‚’é¸æŠœã—ã¦è¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹"""
    today = datetime.date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")
    used_titles = load_used_news()

    # RSSã‹ã‚‰å€™è£œå–å¾—
    candidates = fetch_rss_candidates()

    # é‡è¤‡é™¤å»
    candidates = [c for c in candidates if c["title"] not in used_titles]

    if candidates:
        # RSSå€™è£œã‚’Geminiã«æ¸¡ã—ã¦æœ€é©ãª1ä»¶ã‚’é¸æŠœã•ã›ã‚‹
        candidate_list = "\n".join(
            [f"{i+1}. [{c['source']}] {c['title']} ({c['pub'][:16]})" for i, c in enumerate(candidates[:15])]
        )
        prompt = f"""
ä»¥ä¸‹ã¯ä»Šæ—¥ï¼ˆ{today}ï¼‰ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã§ã™ã€‚
æ—¥æœ¬ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ãƒ‘ãƒ¼ã‚½ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒæœ€ã‚‚è­°è«–ã—ãŸããªã‚‹ã€è³›å¦ãŒåˆ†ã‹ã‚Œã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚’1ä»¶é¸ã‚“ã§ã€è¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å€™è£œãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼š
{candidate_list}

é¸æŠœã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç•ªå·ï¼ˆselected_indexï¼‰ã¨è¨˜äº‹å†…å®¹ã‚’ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§å›ç­”ï¼š
{{
  "selected_index": 1,
  "title": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªã€30æ–‡å­—ä»¥å†…ï¼‰",
  "title_html": "HTMLã‚¿ã‚¤ãƒˆãƒ«ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’<span class=\\"ãƒã‚¤ãƒ©ã‚¤ãƒˆ\\">tagã§å¼·èª¿ï¼‰",
  "hero_lead": "ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆ2ã€‚3è¡Œã€HTMLã®<br>ã‚¿ã‚°ä½¿ç”¨å¯ï¼‰",
  "overview": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®èƒŒæ™¯ãƒ»è©³ç´°ã®èª¬æ˜ï¼ˆ3ã€†5æ–‡ã€èª­è€…ãŒãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã‚’ååˆ†ã«ç†è§£ã§ãã‚‹ã‚ˆã†ã«å…·ä½“çš„ã«è¨˜è¿°ï¼‰",
  "summary_items": [
    "ã‚µãƒãƒª1ï¼ˆ1ã€‚2æ–‡ã§è¦ç‚¹ã‚’ç°¡æ½”ã«ï¼‰",
    "ã‚µãƒãƒª2ï¼ˆ1ã€‚2æ–‡ã§è¦ç‚¹ã‚’ç°¡æ½”ã«ï¼‰",
    "ã‚µãƒãƒª3ï¼ˆ1ã€‚2æ–‡ã§è¦ç‚¹ã‚’ç°¡æ½”ã«ï¼‰"
  ],
  "tags": [
    ["tag-hot", "ã‚¿ã‚°å1"],
    ["tag-tech", "ã‚¿ã‚°å2"],
    ["tag-biz", "ã‚¿ã‚°å3"]
  ],
  "news_summary_short": "Slacké€šçŸ¥ç”¨ã®çŸ­ã„èª¬æ˜ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰"
}}
"""
        raw = call_gemini(prompt)
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã«ã‚‚å¯¾å¿œ
        raw_clean = re.sub(r'^```[\w]*\n?', '', raw.strip(), flags=re.MULTILINE)
        raw_clean = re.sub(r'```$', '', raw_clean.strip())
        match = re.search(r'\{{[\s\S]*\}}', raw_clean)
        if not match:
            print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹é¸æŠœå¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹:", raw[:500])
            sys.exit(1)
        result = json.loads(match.group())

        # é¸æŠœã•ã‚ŒãŸå€™è£œã®ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒãƒ¼ã‚¸
        idx = result.get("selected_index", 1) - 1
        if 0 <= idx < len(candidates):
            selected = candidates[idx]
            result["source_name"] = selected["source"]
            result["source_url"] = selected["link"]
        else:
            result["source_name"] = candidates[0]["source"]
            result["source_url"] = candidates[0]["link"]

        # ä½¿ç”¨æ¸ˆã¿ã«è¨˜éŒ²
        save_used_news(used_titles, result["title"])
        return result

    else:
        # RSSãŒä½¿ãˆãªã„å ´åˆã¯Geminiå˜ç‹¬ã§ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        print("âš ï¸ RSSå€™è£œãªã—ã€‚Geminiå˜ç‹¬ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ç”Ÿæˆã€‚")
        used_str = "\n".join([f"- {t}" for t in used_titles[-10:]]) if used_titles else "ãªã—"
        prompt = f"""
ä»Šæ—¥ï¼ˆ{today}ï¼‰æ™‚ç‚¹ã§æœ€ã‚‚ãƒ›ãƒƒãƒˆãªAIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’1ä»¶é¸ã‚“ã§ãã ã•ã„ã€‚
æ¡ä»¶ï¼šç›´è¿‘1é€±é–“ä»¥å†…ã€æ—¥æœ¬ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ãƒ‘ãƒ¼ã‚½ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒé–¢å¿ƒã‚’æŒã¤è©±é¡Œã€è­°è«–ã‚’å‘¼ã¶ãƒˆãƒ”ãƒƒã‚¯ã€‚

ä¸‹è¨˜ã¯éå»ã«ä½¿ç”¨æ¸ˆã¿ãªã®ã§é¸ã°ãªã„ã§ãã ã•ã„ï¼š
{used_str}

JSONå½¢å¼ã®ã¿ã§å›ç­”ï¼š
{{
  "title": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªã€30æ–‡å­—ä»¥å†…ï¼‰",
  "title_html": "HTMLã‚¿ã‚¤ãƒˆãƒ«ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’<span class=\\"ãƒã‚¤ãƒ©ã‚¤ãƒˆ\\">tagã§å¼·èª¿ï¼‰",
  "hero_lead": "ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆ2ã€‚3è¡Œï¼‰",
  "overview": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®èƒŒæ™¯ãƒ»è©³ç´°ã®èª¬æ˜ï¼ˆ3ã€†5æ–‡ã€èª­è€…ãŒå†…å®¹ã‚’ååˆ†ã«ç†è§£ã§ãã‚‹ã‚ˆã†ã«å…·ä½“çš„ã«ï¼‰",
  "summary_items": ["ã‚µãƒãƒª1", "ã‚µãƒãƒª2", "ã‚µãƒãƒª3"],
  "tags": [["tag-hot", "ã‚¿ã‚°å1"], ["tag-tech", "ã‚¿ã‚°å2"], ["tag-biz", "ã‚¿ã‚°å3"]],
  "news_summary_short": "Slacké€šçŸ¥ç”¨ã®çŸ­ã„èª¬æ˜ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
  "source_name": "æƒ…å ±æºãƒ¡ãƒ‡ã‚£ã‚¢å",
  "source_url": "æƒ…å ±æºURL"
}}
"""
        raw = call_gemini(prompt)
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã«ã‚‚å¯¾å¿œ
        raw_clean = re.sub(r'^```[\w]*\n?', '', raw.strip(), flags=re.MULTILINE)
        raw_clean = re.sub(r'```$', '', raw_clean.strip())
        match = re.search(r'\{{[\s\S]*\}}', raw_clean)
        if not match:
            print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹:", raw[:500])
            sys.exit(1)
        result = json.loads(match.group())
        save_used_news(used_titles, result["title"])
        return result

# ===== ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ =====
def generate_reviews(news: dict) -> dict:
    """6åã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«ã‚ˆã‚‹ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹"""
    prompt = f"""
ã‚ãªãŸã¯ã€ŒThe Juryã€ã¨ã„ã†AIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ã‚°ã®ç·¨é›†AIã§ã™ã€‚
ä»¥ä¸‹ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ã„ã¦ã€6åã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãã‚Œãã‚Œã®è¦–ç‚¹ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {news['title']}
è¦ç´„: {' '.join(news['summary_items'])}

ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‘
1. çŸ³æ©‹ å©ï¼ˆã„ã—ã°ã— ãŸãŸãï¼‰: å®ˆæ—§æ´¾PM/50ä»£ã€‚ã€Œæ˜”ã¯ã‚ˆã‹ã£ãŸã€ãŒå£ç™–ã€‚æ–°æŠ€è¡“ã«æ‡ç–‘çš„ã ãŒã€ç¾å ´è¦–ç‚¹ã§ã¯ä¸€ç†ã‚ã‚‹æ„è¦‹ã‚’è¨€ã†ã€‚
2. ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¼ãƒ­: å¤©æ‰ãƒãƒƒã‚«ãƒ¼/20ä»£ã€‚æŠ€è¡“ã‚ªã‚¿ã‚¯ã€‚ã€ŒæŠ€è¡“ã¯æ­¢ã¾ã‚‰ãªã„ã€ã€‚çŸ³æ©‹ã‚’è€å®³ã¨æ€ã£ã¦ã„ã‚‹ã€‚
3. é»’å­— ç­–ï¼ˆãã‚ã˜ ã¯ã‹ã‚‹ï¼‰: å†·å¾¹ã‚³ãƒ³ã‚µãƒ«/30ä»£ã€‚ã€Œé‡‘ã«ãªã‚‹ã‹ï¼Ÿã€ãŒåˆ¤æ–­åŸºæº–ã€‚å¸‚å ´ãƒ»ROIè¦–ç‚¹ã€‚
4. ãƒ‘ã‚±ãƒƒãƒˆå®ˆï¼ˆã±ã‘ã£ã¨ ã¾ã‚‚ã‚‹ï¼‰: NWè·äºº/40ä»£ã€‚ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»ç¾å ´å®Ÿè£…ã®è¦³ç‚¹ã€‚ã€Œã‚¤ãƒ³ãƒ•ãƒ©ãŒæ­»ã‚“ã ã‚‰å…¨éƒ¨çµ‚ã‚ã‚Šã€ã€‚
5. ãƒ”ãƒ¥ã‚¢: æ–°äººç¤¾å“¡/20ä»£å¥³æ€§ã€‚ç›´æ„Ÿçš„ã«åå¿œã€‚ã€Œæ€–ã„ã€ã€Œä¾¿åˆ©ãã†ã€ã€‚èª­è€…ã®ç´ æœ´ãªç–‘å•ã‚’ä»£å¼ã€‚
6. è¦å¾‹ æ­£ï¼ˆãã‚Šã¤ ãŸã ã—ï¼‰: ã‚³ãƒ³ãƒ—ãƒ©æ‹…å½“/40ä»£ã€‚æ³•çš„ãƒªã‚¹ã‚¯ã«æ•æ„Ÿã€‚ã€Œè‘—ä½œæ¨©ã€ã€Œæƒ…å ±æ¼æ´©ã€ã€ŒGDPR/AI Actã€ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ï¼ˆradarã¯ä¸è¦ã€scoresã¨reviewsã®ã¿ï¼‰ï¼š
{{
  "scores": {{
    "ishibashi": ç‚¹æ•°(1-10ã®æ•´æ•°),
    "zero": ç‚¹æ•°(1-10ã®æ•´æ•°),
    "kokuji": ç‚¹æ•°(1-10ã®æ•´æ•°),
    "packet": ç‚¹æ•°(1-10ã®æ•´æ•°),
    "pure": ç‚¹æ•°(1-10ã®æ•´æ•°),
    "kitsu": ç‚¹æ•°(1-10ã®æ•´æ•°)
  }},
  "reviews": {{
    "ishibashi": "çŸ³æ©‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€è¾›å£ï¼‰",
    "zero": "ã‚¼ãƒ­ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€æŠ€è¡“çš„ï¼‰",
    "kokuji": "é»’å­—ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€ãƒ“ã‚¸ãƒã‚¹è¦–ç‚¹ï¼‰",
    "packet": "ãƒ‘ã‚±ãƒƒãƒˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€ã‚¤ãƒ³ãƒ•ãƒ©è¦–ç‚¹ï¼‰",
    "pure": "ãƒ”ãƒ¥ã‚¢ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€ç´ æœ´ãªç–‘å•ï¼‰",
    "kitsu": "è¦å¾‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ350ã€œ400æ–‡å­—ã€å£èªä½“ã€æ³•çš„è¦–ç‚¹ï¼‰"
  }}
}}
"""
    raw = call_gemini(prompt)
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã«ã‚‚å¯¾å¿œ
    raw_clean = re.sub(r'^```[\w]*\n?', '', raw.strip(), flags=re.MULTILINE)
    raw_clean = re.sub(r'```$', '', raw_clean.strip())
    match = re.search(r'\{[\s\S]*\}', raw_clean)
    if not match:
        print("âŒ ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆå¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹:", raw[:500])
        sys.exit(1)
    result = json.loads(match.group())

    # radarãƒ‡ãƒ¼ã‚¿ã¯ã‚¹ã‚³ã‚¢ã‹ã‚‰è‡ªå‹•ç”Ÿæˆï¼ˆAPIã«é ¼ã‚‰ãšç¢ºå®Ÿã«ç”Ÿæˆï¼‰
    scores = result.get("scores", {})
    char_configs = [
        # (id, name, color, [æŠ€è¡“é©æ–°æ€§ä¿‚æ•°, ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ä¿‚æ•°, ãƒªã‚¹ã‚¯åº¦ä¿‚æ•°, ç¤¾ä¼šçš„å½±éŸ¿ä¿‚æ•°, ç¾å ´å®Ÿç”¨æ€§ä¿‚æ•°, å€«ç†æ³•çš„å•é¡Œä¿‚æ•°])
        # å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¦–ç‚¹ã«å¿œã˜ãŸä¿‚æ•°ã§ã‚¹ã‚³ã‚¢ã‚’å¤‰æ›
        ("ishibashi", "çŸ³æ©‹ å©",   "#a1887f", [0.6, 0.8, 1.2, 0.9, 1.1, 0.8]),
        ("zero",      "ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¼ãƒ­", "#00d4ff", [1.3, 0.9, 0.7, 0.8, 1.1, 0.6]),
        ("kokuji",    "é»’å­— ç­–",    "#ffd166", [0.8, 1.3, 0.9, 0.9, 0.9, 0.7]),
        ("packet",    "ãƒ‘ã‚±ãƒƒãƒˆå®ˆ",  "#06d6a0", [1.0, 0.7, 1.1, 0.8, 1.3, 0.9]),
        ("pure",      "ãƒ”ãƒ¥ã‚¢",     "#c77dff", [1.0, 1.0, 1.0, 1.1, 1.0, 0.9]),
        ("kitsu",     "è¦å¾‹ æ­£",    "#4361ee", [0.7, 0.8, 1.3, 1.0, 0.8, 1.4]),
    ]
    radar = []
    for cid, cname, color, factors in char_configs:
        base = scores.get(cid, 5)
        data = [min(10, max(1, round(base * f))) for f in factors]
        radar.append({"name": cname, "color": color, "data": data})
    result["radar"] = radar
    return result

# ===== åº§è«‡ä¼šç”Ÿæˆ =====
def generate_roundtable(news: dict, reviews: dict) -> dict:
    """6åã«ã‚ˆã‚‹åº§è«‡ä¼šï¼ˆãƒãƒ£ãƒƒãƒˆå½¢å¼ï¼‰ã¨æ ¼è¨€ã‚’ç”Ÿæˆã™ã‚‹"""
    # å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹ã‚’åº§è«‡ä¼šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ³¨å…¥ã—ã¦å§¿å‹¢ã®ä¸€è²«æ€§ã‚’ä¿ã¤
    char_map = {
        "ishibashi": "çŸ³æ©‹ å©",
        "zero":      "ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¼ãƒ­",
        "kokuji":    "é»’å­— ç­–",
        "packet":    "ãƒ‘ã‚±ãƒƒãƒˆå®ˆ",
        "pure":      "ãƒ”ãƒ¥ã‚¢",
        "kitsu":     "è¦å¾‹ æ­£",
    }
    scores = reviews.get("scores", {})
    review_texts = reviews.get("reviews", {})
    stance_summary = ""
    for cid, cname in char_map.items():
        score = scores.get(cid, "?")
        review = review_texts.get(cid, "")
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å…ˆé ­100æ–‡å­—ã‚’å§¿å‹¢è¦ç´„ã¨ã—ã¦ä½¿ç”¨
        summary = review[:100].replace('\n', '') + "â€¦" if len(review) > 100 else review
        stance_summary += f"- {cname}ï¼ˆã‚¹ã‚³ã‚¢{score}/10ï¼‰: {summary}\n"

    prompt = f"""
ã‚ãªãŸã¯ã€ŒThe Juryã€ã¨ã„ã†AIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ã‚°ã®ç·¨é›†AIã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ã„ã¦ã€6åã«ã‚ˆã‚‹æ¿€è«–åº§è«‡ä¼šï¼ˆãƒãƒ£ãƒƒãƒˆå½¢å¼ï¼‰ã¨æ ¼è¨€ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘{news['title']}

ã€å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã§è¡¨æ˜ã—ãŸç«‹å ´ï¼ˆå¿…ãšã“ã®å§¿å‹¢ã‚’åº§è«‡ä¼šã§ã‚‚ä¸€è²«ã•ã›ã‚‹ã“ã¨ï¼‰ã€‘
{stance_summary}
ã€ãƒ«ãƒ¼ãƒ«ã€‘
- 16ã‚¿ãƒ¼ãƒ³ä»¥ä¸Š
- ä¸Šè¨˜ã®å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç«‹å ´ã‚’åº§è«‡ä¼šã§ã‚‚å¿…ãšå¼•ãç¶™ãã“ã¨ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çŸ›ç›¾ã—ãªã„ï¼‰
- æ„è¦‹ã®å¯¾ç«‹æ§‹é€ ã‚’ä½œã‚‹ã“ã¨ï¼ˆç‰¹ã«ã€ŒçŸ³æ©‹ vs ã‚¼ãƒ­ã€ã€Œé»’å­— vs è¦å¾‹ã€ï¼‰
- çŸ³æ©‹ï¼ˆè€å®³ï¼‰ã®æ„è¦‹ã¯ä¸€è¦‹ç†ä¸å°½ã ãŒç¾å ´è¦–ç‚¹ã§ã¯ä¸€ç†ã‚ã‚‹å†…å®¹ã«ã™ã‚‹ã“ã¨
- æœ€å¾Œã¯ã‚³ãƒ³ã‚µãƒ«ï¼ˆé»’å­—ï¼‰ã‹ãƒãƒƒã‚«ãƒ¼ï¼ˆã‚¼ãƒ­ï¼‰ãŒæœªæ¥ã¸ã®ç¤ºå”†ã§å¼·å¼•ã«ç· ã‚ã‚‹ã“ã¨
- å£èªä½“ã§æ„Ÿæƒ…çš„ã«

ã€ã‚­ãƒ£ãƒ©IDã€‘ishibashi=çŸ³æ©‹å©, zero=ã‚³ãƒ¼ãƒ‰ã‚¼ãƒ­, kokuji=é»’å­—ç­–, packet=ãƒ‘ã‚±ãƒƒãƒˆå®ˆ, pure=ãƒ”ãƒ¥ã‚¢, kitsu=è¦å¾‹æ­£

ã€å‡ºåŠ›å½¢å¼ã€‘JSONå½¢å¼ã®ã¿ã§å›ç­”ï¼š
{{
  "chat_log": [
    ["ã‚­ãƒ£ãƒ©ID", "left ã¾ãŸã¯ right", "ç™ºè¨€å†…å®¹"],
    ...
  ],
  "quote": "æœ¬æ—¥ã®æ ¼è¨€ï¼ˆèª­è€…ã®è¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ã€HTMLã®<br>ã‚¿ã‚°ä½¿ç”¨å¯ï¼‰"
}}

â€» leftã¯å·¦å¯„ã‚Šï¼ˆçŸ³æ©‹ãƒ»ãƒ‘ã‚±ãƒƒãƒˆãƒ»è¦å¾‹ï¼‰ã€rightã¯å³å¯„ã‚Šï¼ˆã‚¼ãƒ­ãƒ»é»’å­—ãƒ»ãƒ”ãƒ¥ã‚¢ï¼‰
"""
    raw = call_gemini(prompt)
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã«ã‚‚å¯¾å¿œ
    raw_clean = re.sub(r'^```[\w]*\n?', '', raw.strip(), flags=re.MULTILINE)
    raw_clean = re.sub(r'```$', '', raw_clean.strip())
    match = re.search(r'\{[\s\S]*\}', raw_clean)
    if not match:
        print("âŒ åº§è«‡ä¼šç”Ÿæˆå¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹:", raw[:500])
        sys.exit(1)
    return json.loads(match.group())

# ===== HTMLãƒ“ãƒ«ãƒ‰ =====
def build_html(vol_num: int, news: dict, reviews: dict, roundtable: dict) -> Path:
    """å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸ‹ã‚è¾¼ã‚“ã§HTMLã‚’ç”Ÿæˆã™ã‚‹"""
    template_path = Path(__file__).parent / "template.html"
    template = template_path.read_text(encoding="utf-8")

    # ã‚¢ã‚¤ã‚³ãƒ³ã‚’Base64ã«å¤‰æ›
    icons_dir = Path(__file__).parent / "assets" / "icons"
    icon_b64 = {}
    for name in ["ishibashi", "zero", "kokuji", "packet", "pure", "kitsu"]:
        p = icons_dir / f"{name}.png"
        if p.exists():
            icon_b64[name] = "data:image/png;base64," + base64.b64encode(p.read_bytes()).decode()
        else:
            icon_b64[name] = f"assets/icons/{name}.png"

    scores = reviews["scores"]
    total = round(sum(scores.values()) / len(scores), 1)
    today = datetime.date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")
    vol_str = f"Vol.{vol_num:03d}"
    article_id = f"vol{vol_num:03d}"

    # ã‚¿ã‚°HTML
    tags_html = "\n    ".join(
        f'<span class="tag {cls}">{label}</span>'
        for cls, label in news.get("tags", [])
    )

    def pct(v): return int(v / 10 * 100)

    # æ¦‚è¦ãƒ†ã‚­ã‚¹ãƒˆ
    overview_html = news.get("overview", "")

    # ã‚µãƒãƒªãƒ¼ã‚¢ã‚¤ãƒ†ãƒ 
    summary_html = "\n      ".join(
        f"<li>{item}</li>" for item in news.get("summary_items", [])
    )

    # ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°HTML
    char_names = {
        "ishibashi": "çŸ³æ©‹ å©", "zero": "ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¼ãƒ­",
        "kokuji": "é»’å­— ç­–", "packet": "ãƒ‘ã‚±ãƒƒãƒˆå®ˆ",
        "pure": "ãƒ”ãƒ¥ã‚¢", "kitsu": "è¦å¾‹ æ­£",
    }
    chat_html_parts = []
    for char, side, text in roundtable.get("chat_log", []):
        name = char_names.get(char, char)
        icon_src = icon_b64.get(char, f"assets/icons/{char}.png")
        chat_html_parts.append(f"""      <div class="chat-msg {char} {side}">
        <img src="{icon_src}" alt="{name}" class="chat-icon">
        <div class="chat-bubble-wrap">
          <span class="chat-name">{name}</span>
          <div class="chat-bubble">{text}</div>
        </div>
      </div>""")
    chat_html = "\n".join(chat_html_parts)

    # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
    radar_datasets = []
    for r in reviews.get("radar", []):
        radar_datasets.append({
            "label": r["name"],
            "data": r["data"],
            "borderColor": r["color"],
            "backgroundColor": r["color"] + "22",
            "borderWidth": 2,
            "pointBackgroundColor": r["color"],
            "pointRadius": 3,
        })

    # ã‚½ãƒ¼ã‚¹ãƒªãƒ³ã‚¯
    source_links = f'<a href="{news.get("source_url", "#")}" target="_blank" rel="noopener">{news.get("source_name", "å‚è€ƒè¨˜äº‹")}</a>'
    source_badge = f'<a href="{news.get("source_url", "#")}" target="_blank" rel="noopener">{news.get("source_name", "å‚è€ƒè¨˜äº‹")}</a>'

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç½®æ›
    html = template
    replacements = {
        "{{ARTICLE_TITLE}}": news["title"],
        "{{ARTICLE_TITLE_HTML}}": news.get("title_html", news["title"]),
        "{{ARTICLE_ID}}": article_id,
        "{{VOL_NUMBER}}": vol_str,
        "{{PUBLISH_DATE}}": today,
        "{{NEWS_SUMMARY_SHORT}}": news.get("news_summary_short", ""),
        "{{HERO_LEAD}}": news.get("hero_lead", ""),
        "{{TAGS_HTML}}": tags_html,
        "{{TOTAL_SCORE}}": str(total),
        "{{SCORE_ISHIBASHI}}": str(scores.get("ishibashi", 5)),
        "{{SCORE_ZERO}}": str(scores.get("zero", 5)),
        "{{SCORE_KOKUJI}}": str(scores.get("kokuji", 5)),
        "{{SCORE_PACKET}}": str(scores.get("packet", 5)),
        "{{SCORE_PURE}}": str(scores.get("pure", 5)),
        "{{SCORE_KITSU}}": str(scores.get("kitsu", 5)),
        "{{SCORE_ISHIBASHI_PCT}}": str(pct(scores.get("ishibashi", 5))),
        "{{SCORE_ZERO_PCT}}": str(pct(scores.get("zero", 5))),
        "{{SCORE_KOKUJI_PCT}}": str(pct(scores.get("kokuji", 5))),
        "{{SCORE_PACKET_PCT}}": str(pct(scores.get("packet", 5))),
        "{{SCORE_PURE_PCT}}": str(pct(scores.get("pure", 5))),
        "{{SCORE_KITSU_PCT}}": str(pct(scores.get("kitsu", 5))),
        "{{REVIEW_ISHIBASHI}}": reviews["reviews"].get("ishibashi", ""),
        "{{REVIEW_ZERO}}": reviews["reviews"].get("zero", ""),
        "{{REVIEW_KOKUJI}}": reviews["reviews"].get("kokuji", ""),
        "{{REVIEW_PACKET}}": reviews["reviews"].get("packet", ""),
        "{{REVIEW_PURE}}": reviews["reviews"].get("pure", ""),
        "{{REVIEW_KITSU}}": reviews["reviews"].get("kitsu", ""),
        "{{OVERVIEW}}": overview_html,
        "{{SUMMARY_ITEMS}}": summary_html,
        "{{CHAT_LOG_HTML}}": chat_html,
        "{{RADAR_DATA_JSON}}": json.dumps(radar_datasets, ensure_ascii=False),
        "{{QUOTE_TEXT}}": roundtable.get("quote", ""),
        "{{SOURCE_LINKS}}": source_links,
        "{{SOURCE_BADGE}}": source_badge,
        "{{SUPABASE_URL}}": SUPABASE_URL,
        "{{SUPABASE_ANON_KEY}}": SUPABASE_ANON_KEY,
    }
    for k, v in replacements.items():
        html = html.replace(k, v)

    out_path = Path(__file__).parent / f"vol{vol_num:03d}.html"
    out_path.write_text(html, encoding="utf-8")
    return out_path

# ===== è¨˜äº‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–° =====
def update_index(vol_num: int, news: dict, total_score: float):
    """index.htmlã®è¨˜äº‹ä¸€è¦§ã«æ–°ã—ã„è¨˜äº‹ã‚’è¿½åŠ ã™ã‚‹"""
    index_path = Path(__file__).parent / "index.html"
    today = datetime.date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")
    vol_str = f"Vol.{vol_num:03d}"
    article_id = f"vol{vol_num:03d}"

    new_entry = f"""      <article class="article-card latest">
        <a href="{article_id}.html">
          <div class="card-top">
            <span class="card-vol">{vol_str}</span>
            <span class="badge-latest">LATEST</span>
            <span class="card-date">{today}</span>
          </div>
          <h2 class="card-title">{news['title']}</h2>
          <p class="card-summary">{news.get('news_summary_short', '')}</p>
          <div class="card-score-block">
            <div class="card-score-num">{total_score}</div>
            <div class="card-score-denom">/ 10</div>
            <div class="card-score-label">ç·åˆã‚¹ã‚³ã‚¢</div>
          </div>
        </a>
      </article>"""

    if not index_path.exists():
        # index.htmlãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
        index_html = f"""<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI News Cross-Review "The Jury"</title>
  <style>
    * {{ margin: 0; padding: 0; box-sizing: border-box; }}
    body {{ background: #0d1117; color: #e6edf3; font-family: 'Noto Sans JP', sans-serif; padding: 40px 20px; }}
    .header {{ text-align: center; margin-bottom: 60px; }}
    .header h1 {{ font-size: 2rem; color: #ff4d4d; letter-spacing: 2px; }}
    .header p {{ color: #8b949e; margin-top: 10px; }}
    .articles {{ max-width: 900px; margin: 0 auto; display: grid; gap: 20px; }}
    .article-card {{ background: #161b22; border: 1px solid #30363d; border-radius: 12px; overflow: hidden; transition: transform 0.2s; }}
    .article-card:hover {{ transform: translateY(-4px); }}
    .article-card a {{ display: block; padding: 24px; text-decoration: none; color: inherit; }}
    .card-vol {{ font-size: 12px; color: #ff4d4d; font-weight: 700; margin-bottom: 8px; }}
    .card-title {{ font-size: 1.2rem; font-weight: 700; margin-bottom: 10px; color: #e6edf3; }}
    .card-summary {{ font-size: 14px; color: #8b949e; margin-bottom: 16px; line-height: 1.6; }}
    .card-meta {{ display: flex; justify-content: space-between; font-size: 12px; color: #8b949e; }}
    .card-score {{ color: #ffd166; font-weight: 700; }}
  </style>
</head>
<body>
  <div class="header">
    <h1>AI NEWS CROSS-REVIEW "THE JURY"</h1>
    <p>6åã®AIã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒæœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¾›å£ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼</p>
  </div>
  <div class="articles">
{new_entry}
  </div>
</body>
</html>"""
        index_path.write_text(index_html, encoding="utf-8")
    else:
        # æ—¢å­˜ã®index.htmlã«è¨˜äº‹ã‚’è¿½åŠ ï¼ˆæœ€æ–°ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†å…ˆé ­ã«æŒ¿å…¥ï¼‰
        content = index_path.read_text(encoding="utf-8")
        # æ—¢å­˜ã®latestãƒãƒƒã‚¸ã‚’å±¥æ­´ã‚«ãƒ¼ãƒ‰ã«å¤‰æ›´ï¼ˆæ–°ã—ã„è¨˜äº‹ãŒæœ€æ–°ã«ãªã‚‹ãŸã‚ï¼‰
        content = content.replace('article-card latest', 'article-card')
        content = content.replace('<span class="badge-latest">LATEST</span>', '')
        # æ–°ã—ã„è¨˜äº‹ã‚’å…ˆé ­ã«æŒ¿å…¥
        content = content.replace(
            '<div class="articles">',
            f'<div class="articles">\n{new_entry}'
        )
        index_path.write_text(content, encoding="utf-8")

# ===== Slacké€šçŸ¥ =====
def notify_slack(vol_num: int, news: dict, total_score: float, html_url: str):
    """Slackã«æ–°è¨˜äº‹ã®é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹"""
    if not SLACK_WEBHOOK_URL:
        print("âš ï¸ SLACK_WEBHOOK_URL ãŒæœªè¨­å®šã®ãŸã‚Slacké€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return

    import urllib.request
    vol_str = f"Vol.{vol_num:03d}"
    today = datetime.date.today().strftime("%Y/%m/%d")

    # ã‚¹ã‚³ã‚¢ãƒãƒ¼ï¼ˆçµµæ–‡å­—ã§è¡¨ç¾ï¼‰
    score_bar = "ğŸŸ¥" * int(total_score) + "â¬œ" * (10 - int(total_score))

    payload = {
        "blocks": [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ“° AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ {vol_str} å…¬é–‹ï¼",
                    "emoji": True
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{news['title']}*\n\n{news.get('news_summary_short', '')}"
                }
            },
            {
                "type": "section",
                "fields": [
                    {"type": "mrkdwn", "text": f"*ç·åˆã‚¹ã‚³ã‚¢*\n{score_bar} {total_score}/10"},
                    {"type": "mrkdwn", "text": f"*å…¬é–‹æ—¥*\n{today}"}
                ]
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "ğŸ§± çŸ³æ©‹å© vs ğŸ’» ã‚¼ãƒ­ vs ğŸ’¼ é»’å­—ç­– vs ğŸ“¡ ãƒ‘ã‚±ãƒƒãƒˆå®ˆ vs ğŸŒ± ãƒ”ãƒ¥ã‚¢ vs âš–ï¸ è¦å¾‹æ­£\n6åã®æ¿€è«–ã¯ãƒ–ãƒ­ã‚°ã§ï¼"
                }
            },
            {
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": {"type": "plain_text", "text": "ğŸ“– è¨˜äº‹ã‚’èª­ã‚€", "emoji": True},
                        "url": html_url,
                        "style": "primary"
                    }
                ]
            }
        ]
    }

    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        SLACK_WEBHOOK_URL,
        data=data,
        headers={"Content-Type": "application/json"}
    )
    try:
        with urllib.request.urlopen(req, timeout=30) as resp:
            print(f"âœ… Slacké€šçŸ¥é€ä¿¡å®Œäº†: {resp.status}")
    except Exception as e:
        print(f"âš ï¸ Slacké€šçŸ¥å¤±æ•—ï¼ˆè¨˜äº‹ç”Ÿæˆã¯æˆåŠŸï¼‰: {e}")

# ===== è¨˜äº‹ç•ªå·ã®è‡ªå‹•æ¡ç•ª =====
def get_next_vol_num() -> int:
    """æ—¢å­˜ã®volXXX.htmlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦æ¬¡ã®ç•ªå·ã‚’è¿”ã™"""
    base = Path(__file__).parent
    existing = list(base.glob("vol*.html"))
    if not existing:
        return 2  # vol001ã¯ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦å­˜åœ¨ã™ã‚‹ã®ã§002ã‹ã‚‰
    nums = []
    for f in existing:
        m = re.match(r'vol(\d+)\.html', f.name)
        if m:
            nums.append(int(m.group(1)))
    return max(nums) + 1 if nums else 2

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    print("=" * 50)
    print("ğŸš€ The Jury - è‡ªå‹•è¨˜äº‹ç”Ÿæˆé–‹å§‹")
    print("=" * 50)

    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)

    # 1. æ¬¡ã®è¨˜äº‹ç•ªå·ã‚’æ±ºå®š
    vol_num = get_next_vol_num()
    print(f"\nğŸ“Œ ç”Ÿæˆã™ã‚‹è¨˜äº‹: Vol.{vol_num:03d}")

    # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    print("\nğŸ” æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­...")
    news = fetch_top_ai_news()
    print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—: {news['title']}")

    # 3. ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
    print("\nâœï¸  6åã®ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆä¸­...")
    reviews = generate_reviews(news)
    scores = reviews["scores"]
    total = round(sum(scores.values()) / len(scores), 1)
    print(f"âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆå®Œäº†ï¼ˆç·åˆã‚¹ã‚³ã‚¢: {total}/10ï¼‰")

    # 4. åº§è«‡ä¼šç”Ÿæˆ
    print("\nğŸ’¬ æ¿€è«–ï¼åº§è«‡ä¼šã‚’ç”Ÿæˆä¸­...")
    roundtable = generate_roundtable(news, reviews)
    print(f"âœ… åº§è«‡ä¼šç”Ÿæˆå®Œäº†ï¼ˆ{len(roundtable.get('chat_log', []))}ã‚¿ãƒ¼ãƒ³ï¼‰")

    # 5. HTMLç”Ÿæˆ
    print("\nğŸ”¨ HTMLã‚’ç”Ÿæˆä¸­...")
    out_path = build_html(vol_num, news, reviews, roundtable)
    print(f"âœ… HTMLç”Ÿæˆå®Œäº†: {out_path}")

    # 6. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
    print("\nğŸ“‹ è¨˜äº‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ä¸­...")
    update_index(vol_num, news, total)
    print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å®Œäº†")

    # 7. Slacké€šçŸ¥
    print("\nğŸ“£ Slacké€šçŸ¥ã‚’é€ä¿¡ä¸­...")
    blog_url = f"https://siitake-man.github.io/the-jury/vol{vol_num:03d}.html"
    notify_slack(vol_num, news, total, blog_url)

    print("\n" + "=" * 50)
    print(f"ğŸ‰ å®Œäº†ï¼ Vol.{vol_num:03d} ã‚’å…¬é–‹ã—ã¾ã—ãŸ")
    print(f"   URL: {blog_url}")
    print("=" * 50)

if __name__ == "__main__":
    main()
